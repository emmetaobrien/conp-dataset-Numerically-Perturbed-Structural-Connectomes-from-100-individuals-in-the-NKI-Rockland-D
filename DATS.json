{
    "identifier": {
        "identifier": "https://doi.org/10.5281/zenodo.4041548",
        "identifierSource": "DOI"
    },
    "title": "Numerically Perturbed Structural Connectomes from 100 individuals in the NKI Rockland Dataset",
    "creators": [
        {
            "name": "Kiar, Gregory"
        }
    ],
    "description": "<p>This dataset contains the derived connectomes, discriminability scores, and classification performance for structural connectomes estimated from a subset of the Nathan Kline Institute Rockland Sample dataset, and is associated with an upcoming manuscript entitled:&nbsp;<em>Numerical Instabilities in Analytical Pipelines Compromise the Reliability of Network Neuroscience</em>. The associated code for this project is publicly available at:&nbsp;<a href=\"https://github.com/gkpapers/2020ImpactOfInstability\">https://github.com/gkpapers/2020ImpactOfInstability</a>. For any questions, please contact Gregory Kiar (gkiar07@gmail.com) or Tristan Glatard (tristan.glatard@concordia.ca).</p>\n\n<p>Below is a table of contents describing the contents of this dataset, which is followed by&nbsp;an excerpt from the manuscript pertaining to the contained data.</p>\n\n<ul>\n\t<li>impactofinstability_connect_dset25x2x2x20_inputs.h5 : Connectomes derived from 25 subjects, 2&nbsp;sessions, 2 subsamples, and 20 MCA simulations&nbsp;with input perturbations.</li>\n\t<li>impactofinstability_connect_dset25x2x2x20_pipeline.h5 :&nbsp;Connectomes derived from 25 subjects, 2&nbsp;sessions, 2 subsamples, and 20 MCA simulations&nbsp;with pipeline perturbations.</li>\n\t<li>impactofinstability_discrim_dset25x2x2x20_both.csv : Discriminability scores for each grouping of the 25x2x2x20 dataset.</li>\n\t<li>impactofinstability_connect+feature_dset100x1x1x20_both.h5 :&nbsp;Connectomes and features derived from 100&nbsp;subjects, 1&nbsp;sessions, 1&nbsp;subsamples, and 20 MCA simulations&nbsp;with both&nbsp;perturbation types.</li>\n\t<li>impactofinstability_classif_dset100x1x1x20_both.h5 : Classification performance results for the BMI classification task on the 100x1x1x20 dataset.</li>\n</ul>\n\n<p><strong>Dataset</strong><br>\nThe Nathan Kline Institute Rockland Sample (NKI-RS) dataset [1] contains high-fidelity imaging and phenotypic data from over 1,000 individuals spread across the lifespan. A subset of this dataset was chosen for each experiment to both match sample sizes presented in the original analyses and to minimize the computational burden of performing MCA. The selected subset comprises 100 individuals ranging in age from 6 &ndash; 79 with a mean of 36.8 (original: 6 &ndash; 81, mean 37.8), 60% female (original: 60%), with 52% having a BMI over 25 (original: 54%).</p>\n\n<p>Each selected individual had at least a single session of both structural T1-weighted (MPRAGE) and diffusion-weighted (DWI) MR imaging data. DWI data was acquired with 137 diffusion directions; more information regarding the acquisition of this dataset can be found in the NKI-RS data release [1].</p>\n\n<p>In addition to the 100 sessions mentioned above, 25 individuals had &nbsp;a second session to be used in a test-retest analysis. Two additional copies of the data for these individuals were generated, including only the odd or even diffusion directions (64 + 9 B0 volumes = 73 in either case). This allows an extra level of stability evaluation to be performed between the levels of MCA and session-level variation.</p>\n\n<p>In total, the dataset is composed of 100 diffusion-downsampled sessions of data originating from 50 acquisitions and 25 individuals for in depth stability analysis, and an additional 100 sessions of full-resolution data from 100 individuals for subsequent analyses.</p>\n\n<p><strong>Processing</strong><br>\nThe dataset was preprocessed using a standard FSL [2] workflow consisting of eddy-current correction and alignment. The MNI152 atlas was aligned to each session of data, and the resulting transformation was applied to the DKT parcellation [3]. Downsampling the diffusion data took place after preprocessing was performed on full-resolution sessions, ensuring that an additional confound was not introduced in this process when comparing between downsampled sessions. The preprocessing described here was performed once without MCA, and thus is not being evaluated.</p>\n\n<p>Structural connectomes were generated from preprocessed data using two canonical pipelines from Dipy [4]: deterministic and probabilistic. In the deterministic pipeline, a constant solid angle model was used to estimate tensors at each voxel and streamlines were then generated using the EuDX algorithm [5]. In the probabilistic pipeline, a constrained spherical deconvolution model was fit at each voxel and streamlines were generated by iteratively sampling the resulting fiber orientation distributions. In both cases tracking occurred with 8 seeds per 3D voxel and edges were added to the graph based on the location of terminal nodes with weight determined by fiber count.</p>\n\n<p><strong>Perturbations</strong><br>\nAll connectomes were generated with one reference execution where no perturbation was introduced in the processing. For all other executions, all floating point operations were instrumented with Monte Carlo Arithmetic (MCA) [6] through Verificarlo [7]. MCA simulates the distribution of errors implicit to all instrumented floating point operations (flop).</p>\n\n<p>MCA can be introduced in two places for each flop: before or after evaluation. Performing MCA on the inputs of an operation limits its precision, while performing MCA on the output of an operation highlights round-off errors that may be introduced. The former is referred to as Precision Bounding (PB) and the latter is called Random Rounding (RR).</p>\n\n<p>Using MCA, the execution of a pipeline may be performed many times to produce a distribution of results. Studying the distribution of these results can then lead to insights on the stability of the instrumented tools or functions. To this end, a complete software stack was instrumented with MCA and is made available on GitHub through https://github.com/gkiar/fuzzy.</p>\n\n<p>Both the RR and PB variants of MCA were used independently for all experiments. As was presented in [8], both the degree of instrumentation (i.e. number of affected libraries) and the perturbation mode have an effect on the distribution of observed results. For this work, the RR-MCA was applied across the bulk of the relevant libraries and is referred to as Pipeline Perturbation. In this case the bulk of numerical operations were affected by MCA.</p>\n\n<p>Conversely, the case in which PB-MCA was applied across the operations in a small subset of libraries is here referred to as Input Perturbation. In this case, the inputs to operations within the instrumented libraries (namely, Python and Cython) were perturbed, resulting in less frequent, data-centric perturbations. Alongside the stated theoretical differences, Input Perturbation is considerably less computationally expensive than Pipeline Perturbation.</p>\n\n<p>All perturbations were targeted the least-significant-bit for all data (t=24and t=53in float32 and float64, respectively [7]). Simulations were performed between 10 and 20 times for each pipeline execution, depending on the experiment. A detailed motivation for the number of simulations can be found in [9].</p>\n\n<p><strong>Evaluation</strong><br>\nThe magnitude and importance of instabilities in pipelines can be considered at a number of analytical levels, namely: the induced variability of derivatives directly, the resulting downstream impact on summary statistics or features, or the ultimate change in analyses or findings. We explore the nature and severity of instabilities through each of these lenses. Unless otherwise stated, all p-values were computed using Wilcoxon signed-rank tests.</p>\n\n<p>&nbsp; &nbsp; <strong>Direct Evaluation of the Graphs</strong><br>\nThe differences between simulated graphs was measured directly through both a direct variance quantification and a comparison to other sources of variance such as individual- and session-level differences.</p>\n\n<p>Quantification of Variability &ndash; Graphs, in the form of adjacency matrices, were compared to one another using three metrics: normalized percent deviation, Pearson correlation, and edgewise significant digits. The normalized percent deviation measure, defined in [8], scales the norm of the difference between a simulated graph and the reference execution (that without intentional perturbation) with respect to the norm of the reference graph. The purpose of this comparison is to provide insight on the scale of differences in observed graphs relative to the original signal intensity. A Pearson correlation coefficient was computed in complement to normalized percent deviation to identify the consistency of structure and not just intensity between observed graphs. Finally, the estimated number of significant digits for each edge in the graph was computed. The upper bound on significant digits is 15.7 for 64-bit floating point data.</p>\n\n<p>The percent deviation, correlation, and number of significant digits were each calculated within a single session of data, thereby removing any subject- and session-effects and providing a direct measure of the tool-introduced variability across perturbations. A distribution was formed by aggregating these individual results.</p>\n\n<p>Class-based Variability Evaluation &ndash; To gain a concrete understanding of the significance of observed variations we explore the separability of our results with respect to understood sources of variability, such as &nbsp;subject-, session-, and pipeline-level effects. This can be probed through Discriminability [10], a technique similar to ICC which relies on the mean of a ranked distribution of distances between observations belonging to a defined set of classes.</p>\n\n<p>Discriminability can then be interpreted&nbsp;as the probability that an observation belonging to a given class will be more similar to other observations within that class than observations of a different class. It is a measure of reproducibility, and is discussed in detail in [10].</p>\n\n<p>This definition allows for the exploration of deviations across arbitrarily defined classes which in practice can be any of those listed above. We combine this statistic with permutation testing to test hypotheses on whether differences between classes are statistically significant in each of these settings.</p>\n\n<p>With this in mind, three hypotheses were defined. For each setting, we state the alternate hypotheses, the variable(s) which will be used to determine class membership, and the remaining variables which may be sampled when obtaining multiple observations. Each hypothesis was tested independently for each pipeline and perturbation mode, and in every case where it is possible the hypotheses were tested using the reference executions alongside using MCA.</p>\n\n<ol>\n\t<li>Individual Variation<br>\n\tHA: Individuals are distinct from one another.<br>\n\tClass definition: Subject ID.<br>\n\tExperiments: Session (1 subsample), Direction (1 subsample), MCA (1 subsample, 1 session).</li>\n\t<li>Session Variation<br>\n\tHA: Sessions within an individual are distinct.<br>\n\tClass definition: Session ID | Subject ID.<br>\n\tExperiments: Subsample, MCA (1 subsample).</li>\n\t<li>Subsample Variation<br>\n\tHA: Direction subsamples within an acquisition are distinct.<br>\n\tClass definition: Subsample | Subject ID, Session ID.<br>\n\tExperiments: MCA.</li>\n</ol>\n\n<p>As a result, we tested 3 hypotheses across 6 MCA experiments and 3 reference experiments on 2 pipelines and 2 perturbation modes, resulting in a total of 30 distinct tests.</p>\n\n<p><strong>&nbsp; &nbsp; Evaluating Graph-Theoretical Metrics</strong><br>\nWhile connectomes may be used directly for some analyses, it is common practice to summarize them with structural measures, which can then be used as lower-dimensional proxies of connectivity in so-called graph-theoretical studies [11]. We explored the stability of several commonly-used univariate (graphwise) and multivariate (nodewise or edgewise) features. The features computed and subsequent methods for comparison in this section were selected to closely match those computed in [12].</p>\n\n<p>Univariate Differences &ndash; For each univariate statistic (edge count, mean clustering coefficient, global efficiency, modularity, assortativity, and mean path length) a distribution of values across all perturbations within subjects was observed. A Z-score was computed for each sample with respect to the distribution of feature values within an individual, and the proportion of &quot;classically significant&quot; Z-scores, i.e. corresponding to p &lt; 0.05, was reported and aggregated across all subjects. The number of significant digits contained within an estimate derived from a single subject were calculated and aggregated.</p>\n\n<p>Multivariate Differences &ndash; In the case of both nodewise (degree distribution, clustering coefficient, betweenness centrality) and edgewise (weight distribution, connection length) features, the cumulative density functions of their distributions were evaluated over a fixed range and subsequently aggregated across individuals. The number of significant digits for each moment of these distributions (sum, mean, variance, skew, and kurtosis) were calculated across observations within a sample and aggregated.</p>\n\n<p><strong>&nbsp; &nbsp; Evaluating A Complete Analysis</strong><br>\nThough each of the above approaches explores the instability of derived connectomes and their features, many modern studies employ modeling or machine-learning approaches, for instance to learn brain-behavior relationships or identify differences across groups. We carried out one such study and explored the instability of its results with respect to the upstream variability of connectomes characterized in the previous sections. We performed the modeling task with a single sampled connectome per individual and repeated this sampling and modelling 20 times. We report the model performance for each sampling of the dataset and summarize its variance.</p>\n\n<p>BMI Classification &ndash; Structural changes have been linked to obesity in adolescents and adults [13]. We classified normal-weight and overweight individuals from their structural networks (using for overweight a cutoff of BMI &gt; 25 [14]). We reduced the dimensionality of the connectomes through principal component analysis (PCA), and provided the first N-components to a logistic regression classifier for predicting BMI class membership, similar to methods shown in [14], [15]. The number of components was selected as the minimum set which explained &gt; 90% of the variance when averaged across the training set for each fold within the cross validation of the original graphs; this resulted in a feature of 20 components. We trained the model using k-fold cross validation, with k = 2, 5, 10, and N (equivalent to leave-one-out; LOO).</p>",
    "version": "None",
    "licenses": [
        {
            "name": "CC-BY-4.0"
        }
    ],
    "keywords": [
        {
            "value": "canadian-open-neuroscience-platform"
        },
        {
            "value": "neuroimaging"
        },
        {
            "value": "dataset"
        },
        {
            "value": "connectomes"
        },
        {
            "value": "network-neuroscience"
        }
    ],
    "distributions": [
        {
            "formats": [
                "H5",
                "CSV"
            ],
            "size": 1.7,
            "unit": {
                "value": "GB"
            },
            "access": {
                "landingPage": "https://zenodo.org/record/4041549",
                "authorizations": [
                    {
                        "value": "public"
                    }
                ]
            }
        }
    ],
    "extraProperties": [
        {
            "category": "logo",
            "values": [
                {
                    "value": "https://about.zenodo.org/static/img/logos/zenodo-gradient-round.svg"
                }
            ]
        },
		{
            "category": "origin_institution",
            "values": [
                {
                    "value": "McGill University"
                }
            ]
        },
        {
            "category": "origin_city",
            "values": [
                {
                    "value": "Montreal"
                }
            ]
        },
        {
            "category": "origin_province",
            "values": [
                {
                    "value": "Quebec"
                }
            ]
        },
        {
            "category": "origin_country",
            "values": [
                {
                    "value": "Canada"
                }
            ]
        },
		{
            "category": "CONP_status",
            "values": [
                {
                    "value": "CONP"
                }
            ]
        },
        {
            "category": "files",
            "values": [
                {
                    "value": "5"
                }
            ]
        }
    ],
    "types": [
        {
            "value": "unknown"
        }
    ]
}
